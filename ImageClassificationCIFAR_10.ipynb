{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T2Z3E30x3OnR"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"ayush1220/cifar10\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGeuqPc_32DW",
        "outputId": "de34af31-2586-434d-8a9a-99224518d46b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/cifar10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Contents:\", os.listdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChZKHI9zKbRj",
        "outputId": "2ff0eb4d-7cca-4ee7-84db-fbed18396f15"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents: ['cifar10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subdirs = os.listdir(path)\n",
        "for sub in subdirs:\n",
        "    print(sub, \"=>\", os.listdir(os.path.join(path, sub)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXGD4GPHKiU3",
        "outputId": "e6e4e638-3133-4dd4-f68b-f46c97c31db1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar10 => ['test', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define directories\n",
        "base_dir = os.path.join(path, 'cifar10')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ],
      "metadata": {
        "id": "rtF1OYMA6PLD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "img_height, img_width = 32, 32\n",
        "batch_size = 64\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "uPtDE0DX6QOx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    shear_range=0.1,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "mis7kQC26UjO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No augmentation for testing (only rescale)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "AF9koDbqGFz1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MthmmPlpGTGR",
        "outputId": "5518e686-106f-4d5a-f9a2-ea1d9c9d485c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50000 images belonging to 10 classes.\n",
            "Found 10000 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model with dropout\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7gL8BTGMY2m",
        "outputId": "9a27a9b3-69a1-4466-ef32-d0ad5934b763"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1)"
      ],
      "metadata": {
        "id": "LnHGWOppMgJO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stop, lr_reduce]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz1V7mrPMkIz",
        "outputId": "d1061178-26d1-4dcd-b364-f0fc04d53882"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 306ms/step - accuracy: 0.2528 - loss: 1.9875 - val_accuracy: 0.4715 - val_loss: 1.4410 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 100ms/step - accuracy: 0.4452 - loss: 1.5440 - val_accuracy: 0.5201 - val_loss: 1.3152 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 96ms/step - accuracy: 0.5027 - loss: 1.4084 - val_accuracy: 0.5833 - val_loss: 1.1607 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 96ms/step - accuracy: 0.5308 - loss: 1.3255 - val_accuracy: 0.6195 - val_loss: 1.0665 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 97ms/step - accuracy: 0.5544 - loss: 1.2704 - val_accuracy: 0.6431 - val_loss: 1.0173 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 96ms/step - accuracy: 0.5728 - loss: 1.2131 - val_accuracy: 0.6598 - val_loss: 0.9653 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 102ms/step - accuracy: 0.5888 - loss: 1.1795 - val_accuracy: 0.6764 - val_loss: 0.9187 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 98ms/step - accuracy: 0.6005 - loss: 1.1414 - val_accuracy: 0.6690 - val_loss: 0.9473 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6041 - loss: 1.1385\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 99ms/step - accuracy: 0.6041 - loss: 1.1385 - val_accuracy: 0.6379 - val_loss: 1.0424 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 97ms/step - accuracy: 0.6312 - loss: 1.0674 - val_accuracy: 0.6863 - val_loss: 0.8986 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 100ms/step - accuracy: 0.6386 - loss: 1.0444 - val_accuracy: 0.6924 - val_loss: 0.8862 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 95ms/step - accuracy: 0.6468 - loss: 1.0218 - val_accuracy: 0.7101 - val_loss: 0.8330 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 98ms/step - accuracy: 0.6478 - loss: 1.0170 - val_accuracy: 0.7065 - val_loss: 0.8460 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6508 - loss: 1.0065\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 95ms/step - accuracy: 0.6508 - loss: 1.0066 - val_accuracy: 0.7073 - val_loss: 0.8451 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 98ms/step - accuracy: 0.6632 - loss: 0.9791 - val_accuracy: 0.7286 - val_loss: 0.7901 - learning_rate: 2.5000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 99ms/step - accuracy: 0.6659 - loss: 0.9598 - val_accuracy: 0.7243 - val_loss: 0.7981 - learning_rate: 2.5000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6703 - loss: 0.9656\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 99ms/step - accuracy: 0.6703 - loss: 0.9656 - val_accuracy: 0.7191 - val_loss: 0.8086 - learning_rate: 2.5000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 98ms/step - accuracy: 0.6744 - loss: 0.9412 - val_accuracy: 0.7275 - val_loss: 0.7945 - learning_rate: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training history plot\n",
        "plt.figure(figsize=(20, 8))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "PD9XBi1c1FCq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLYx2V-IMopx",
        "outputId": "836dde2c-7df3-4dc8-aee8-03114f6e15d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.7080 - loss: 0.8418\n",
            "Test Accuracy: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snoSCWPkMu9e",
        "outputId": "f3fb09f5-026d-46b8-ff3d-177f8e378a38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix (save as image)\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.savefig(\"confusion_matrix.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "1-rGEQ0VYm23"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gZUWMheYqdD",
        "outputId": "27f8b710-0922-4821-81ee-9ddc20ddc99c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.79      0.77      0.78      1000\n",
            "  automobile       0.83      0.90      0.86      1000\n",
            "        bird       0.75      0.49      0.59      1000\n",
            "         cat       0.58      0.46      0.51      1000\n",
            "        deer       0.71      0.67      0.69      1000\n",
            "         dog       0.71      0.54      0.61      1000\n",
            "        frog       0.60      0.92      0.73      1000\n",
            "       horse       0.74      0.80      0.77      1000\n",
            "        ship       0.82      0.89      0.85      1000\n",
            "       truck       0.78      0.86      0.81      1000\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.72     10000\n",
            "weighted avg       0.73      0.73      0.72     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "pI8R7qza0qsN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample predictions visualization\n",
        "x_test, y_test_true = next(test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=10000,  # load all images\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        "))\n",
        "\n",
        "y_test_true_classes = np.argmax(y_test_true, axis=1)\n",
        "y_test_pred_classes = np.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "# Random 16 images\n",
        "indices = random.sample(range(len(x_test)), 16)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i, idx in enumerate(indices):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(x_test[idx])\n",
        "    plt.title(f'True: {class_labels[y_test_true_classes[idx]]}\\nPred: {class_labels[y_test_pred_classes[idx]]}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('sample_predictions.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqeGQ5Z5ryYY",
        "outputId": "00274abb-65a6-4bb9-a55d-42fc9b6540ae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 10 classes.\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    }
  ]
}